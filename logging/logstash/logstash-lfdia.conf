input {
   beats {
      port => 5044
	  id => "filebeat"
	  type => filebeat
   }
   beats {
      port => 5045
	  id => "processing"
	  type => filebeat
      add_field => { "[@metadata][process]" => true }
   }
   http {
      port => 5046
	  id => "fluentbit"
	  type => fluentbit
   }
}
filter {
  if [type] == "readiness" {
    drop {}
  } else if [type] == "fluentbit" {
    date {
        match => [ "date", "UNIX" ]
        remove_field => [ "date" ]
    }
    mutate {
        remove_field => [ "headers", "host", "type" ]
    }
  } else if [type] == "filebeat" {
    mutate { # 'msg' field name was used to circumvent an issue
				 # when trying to process an incomming field named
				 # 'message'.
        rename => { "msg" => "message" }
    }
    if [@metadata][process] {
	# Process 'msg' field comming from Filebeat and separate its fields
	# and pass them over to Elasticsearch.
        mutate { # Remove trailing whitespaces.
            strip => [ "[message]" ]
        }
        dissect { # Dissect message according to message format:
                  # @CY-@Cm-@CdT​@Ch:@Cn:@Cs.@Ck@Cz @Sl @Cb
                  # @CY-@Cm-@CdT​@Ch:@Cn:@Cs.@Ck@Cz -- timestamp
                  # @Sl -- PayloadMatedPair
                  # @Cb -- comma separated values (CSV) message part
                  # CSV part format 1: callee,caller,call_id,context_id,termination_id,reason
                  # Sample 1:
                  # 2021-06-28T16:10:32.519+0000 PayloadMatedPair=1 sip:+58555408658@xm.va;user=phone,sip:+19392560756@ubqabfx.sdou.jwg.q.mk;user=phone,glb65kd8530qlai5kalot9dcpvrux7u9,2156988,ip/730/402/2146359,media_inactivity​
                  # CSV part format 2: context_id,termination_id,reason
                  # Sample 2:
                  # 2021-06-28T16:10:22.509+0000 PayloadMatedPair=3 311885,ip/867/966/8027539,normal_oab_process
          mapping => {
            "message" => "%{[msg][ts]} PayloadMatedPair=%{[msg][payloadmatedpair]} %{[msg][k1]},%{[msg][k2]},%{[msg][rest]}"
          } # As there are two formats, only the first two comma separated values are assigned to keys here.
          remove_field => [ "message" ]
        }
        date { # Parse date field.
          match => [ "[msg][ts]", "ISO8601" ]
          remove_field => [ "[msg][ts]" ]
        }
        csv { # Separate the rest of the comma separated values.
          columns => ["[msg][k3]","[msg][k4]","[msg][k5]","[msg][k6]"]
	      source => "[msg][rest]"
          remove_field => [ "[msg][rest]" ]
        }
        if [msg][k4] { # Assign proper names for the vales when there were 6 of them.
          mutate {
            rename => { "[msg][k1]" => "[msg][callee]" }
            rename => { "[msg][k2]" => "[msg][caller]" }
            rename => { "[msg][k3]" => "[msg][call_id]" }
            rename => { "[msg][k4]" => "[msg][context_id]" }
            rename => { "[msg][k5]" => "[msg][termination_id]" }
            rename => { "[msg][k6]" => "[msg][reason]" }
          }
        } else {
          mutate { # Assign proper names for the vales when there were 3 of them.
            rename => { "[msg][k1]" => "[msg][context_id]" }
            rename => { "[msg][k2]" => "[msg][termination_id]" }
            rename => { "[msg][k3]" => "[msg][reason]" }
          }
        }
        mutate {
          rename => { "msg" => "message" }
        }
	}
    mutate {
      remove_field => [ "@version", "agent", "ecs", "beat", "log", "type", "source", "stream", "offset", "json", "host", "input", "prospector", "tags", "[kubernetes][container][image]", "[kubernetes][labels]" ] # E/// sample does not remove '@version'
    }
  }
  mutate {
    add_field => { "timestamp" => "%{@timestamp}" }
  }
  ruby {
    path => "./adp-json-validation.rb" # TODO: Update path.
    script_params => {
      "decodedJsonField" => "ignore"
      "failTag" => "schema-validation-unknown"
    }
  }
  if [extra_data][asi][log_plane] == "alarm" {
    mutate {
        replace => {"logplane" => "adp-app-asi-logs"}
    }
  } else if [facility] == "log audit" {
     mutate {
        replace => {"logplane" => "adp-app-audit-logs"}
     }
  }
}
output {
   # elasticsearch {
   #    hosts => ["localhost:9200"]
   #    index => "hr_fb-ls-es"
   #    http_compression => true
   # }
   stdout { codec => json_lines }
}